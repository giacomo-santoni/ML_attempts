{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drdf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_drdf(fname):\n",
    "  reader = drdf.DRDF()\n",
    "  reader.read(fname)\n",
    "  events = []\n",
    "  for run in reader.runs:\n",
    "    for event in reader.runs[run]:\n",
    "      hits_map = dict()\n",
    "      for cam, img in reader.runs[run][event].items():\n",
    "        amplitude = img.pixels[:, :, 0] \n",
    "        time = img.pixels[:, :, 1]\n",
    "        hits_map[cam] = amplitude\n",
    "      events.append((event, hits_map))\n",
    "  return events\n",
    "\n",
    "file = load_drdf(\"/Users/giacomosantoni/Desktop/TESI/Progetto_ML/blindcams/response.drdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SumPhotonsAllCams():\n",
    "    all_cam_ev = []\n",
    "    for i in range(len(file)):\n",
    "        all_cam_list = []\n",
    "        sum_cam_all = [0.]#definisco questa lista perchè mi serve dopo\n",
    "        event_i = file[i][1]# così sto considerando file, nell'evento i esimo, la parte di hits_map (che  un dict)\n",
    "        for cam in event_i:\n",
    "            sum_cam_all = sum(map(sum, event_i[cam]))#nella camera x faccio la somma dei fotoni su ogni pixel\n",
    "            all_cam_list.append(sum_cam_all)#ogni somma di fotoni relativa a una camera la aggiungo in una lista di tutte le camere in ogni evento\n",
    "        all_cam_ev.append(all_cam_list)\n",
    "    return all_cam_ev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "def CamList():\n",
    "    cam_list = []\n",
    "    event_i = file[151][1]\n",
    "    for cam in event_i:\n",
    "        if np.any(event_i[cam] != 0.):\n",
    "            cam_list.append(cam)\n",
    "    return cam_list\n",
    "\n",
    "#all_cam_list = SumPhotonsCam1event()\n",
    "cam_list = CamList()\n",
    "print(len(cam_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCALING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "def ScalingData():\n",
    "    sum_photons_all_cams_all_ev = np.array(SumPhotonsAllCams())\n",
    "    sum_photons_not_0_list = []\n",
    "    for i in range(len(sum_photons_all_cams_all_ev)):\n",
    "        if not(np.any(sum_photons_all_cams_all_ev[i])):\n",
    "            continue\n",
    "        sum_photons_not_0_list.append(sum_photons_all_cams_all_ev[i])\n",
    "    sum_photons_not_0 = np.array(sum_photons_not_0_list)\n",
    "    sum_photons_not_0_tr = np.transpose(sum_photons_not_0)\n",
    "\n",
    "    transformer = RobustScaler().fit(sum_photons_not_0_tr)\n",
    "    scaled_data = transformer.transform(sum_photons_not_0_tr)\n",
    "    scaled_data_tr = np.transpose(scaled_data)\n",
    "\n",
    "    n=0\n",
    "    scaled_sum_photons = []\n",
    "    for i in range(len(sum_photons_all_cams_all_ev)):\n",
    "        if np.any(sum_photons_all_cams_all_ev[i]) != 0:\n",
    "            sum_photons_all_cams_all_ev[i]=scaled_data_tr[n]\n",
    "            n += 1\n",
    "    scaled_sum_photons = sum_photons_all_cams_all_ev\n",
    "    return scaled_sum_photons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "scaled_sum_photons = ScalingData()\n",
    "print(len(scaled_sum_photons[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.28/04\n"
     ]
    }
   ],
   "source": [
    "import ROOT as root\n",
    "\n",
    "#sensor1.root è il file; ogni camera è un TTree\n",
    "input_file = root.TFile.Open(\"/Users/giacomosantoni/Desktop/TESI/Progetto_ML/blindcams/sensors.root\", \"READ\")\n",
    "tree = input_file.Get(\"CAM_NB_X1\")\n",
    "entries = tree.GetEntries()\n",
    "\n",
    "cam_list = CamList()\n",
    "\n",
    "nr_photons_list_all_cams_list = []\n",
    "for cam in cam_list:\n",
    "    nr_photons_list = []\n",
    "    tree = input_file.Get(cam)\n",
    "    for i in range(entries):\n",
    "        n = tree.GetEntry(i)\n",
    "        inner_photons = tree.innerPhotons\n",
    "        #if inner_photons: \n",
    "        nr_photons_list.append(inner_photons)\n",
    "    #print(nr_photons_list)\n",
    "    nr_photons_list_all_cams_list.append(nr_photons_list)\n",
    "\n",
    "nr_photons_list_all_cams = np.array(nr_photons_list_all_cams_list)#ho creato una matrice 10.000 colonne (nr eventi) x 76 righe (nr camere). I numeri che vediamo sono i numeri di fotoni che arrivano alla camera\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(nr_photons_list_all_cams[0]))\n",
    "\n",
    "nr_photons_list_all_cams_tr = nr_photons_list_all_cams.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 54)\n",
      "(200, 54)\n",
      "(800, 54)\n",
      "(200, 54)\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, train_labels, val_labels = train_test_split(scaled_sum_photons, nr_photons_list_all_cams_tr, train_size=0.8, random_state=42)\n",
    "#train_labels = ev_cam_state\n",
    "\n",
    "# print(\"TRAIN: \", list(train_ds))\n",
    "# print(\"VALIDATION: \", list(val_ds))\n",
    "\n",
    "#print(len(train_ds[0]),len(val_ds),len(train_labels),len(val_labels))\n",
    "\n",
    "print(train_ds.shape)\n",
    "print(val_ds.shape)\n",
    "print(train_labels.shape)\n",
    "print(val_labels.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
